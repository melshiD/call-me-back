# Session Log: Context-Aware Prompting & Conversation Intelligence
**Date:** 2025-12-03 03:45 EST
**Focus:** Advanced prompting features for better conversation quality

---

## Summary

Continuation of previous session. Deployed Raindrop + Voice Pipeline, created persona prompt audit. This session captured new feature ideas for context-aware conversation handling.

---

## New Feature Ideas (To Implement)

### 1. Silence-Aware Context Injection

**Problem:** When AI responds after user silence, it has no idea WHY it's speaking or how long the silence was.

**Solution:** Inject silence context into system prompt dynamically:

```javascript
// On silence timeout
this.silenceContext = {
  duration: 120, // seconds
  instruction: 'check-in', // 'back-to-topic', 'wrap-up', 'change-topic'
  lastTopic: this.lastDiscussedTopic
};

// In buildFullSystemPrompt()
if (this.silenceContext) {
  const mins = Math.floor(this.silenceContext.duration / 60);
  systemPrompt += `\n\nSILENCE CONTEXT: It's been ${mins} minute(s) since user spoke. `;
  // Add instruction-specific guidance
}
```

**Tactical instructions by context:**
- `check-in`: "Check if they're still there. Keep it casual."
- `back-to-topic`: "Return to: [topic]"
- `wrap-up`: "Offer natural closing"
- `change-topic`: "Pivot to something new"

---

### 2. Real-Time Conversation State Injection ("Announcer Context")

**Problem:** LLM only sees transcript - misses tone, pacing, emotional arc of conversation.

**Solution:** Add internal "announcer briefing" section that summarizes:
- Where we are in the conversation (early, mid, wrapping up)
- Tone of current exchange (heated, reflective, playful, tense)
- Brief meta-summary of what's happened
- WHY the user might have said what they said (inference amplification)

**Example injection:**
```
CONVERSATION STATE (internal - not shown to user):
You're about 8 minutes into this call. The user started frustrated about work,
vented for a few minutes, and now seems calmer after you validated their feelings.
Current tone: reflective, slightly tired. They just said "I don't know what to do"
- this sounds like they're looking for direction, not more validation.
Adjust your response to be more action-oriented.
```

**Purpose:** Helps LLM understand not just WHAT was said, but the emotional/conversational context of WHY it was said, enabling better bedside manner calibration.

**Storage:** Internal only - not displayed in any dashboard. Could be:
- Generated by lightweight inference pass
- Rule-based from transcript analysis
- Combination of both

---

### 3. Smart Summary Integration (Future)

Past conversation summaries will feed into context, but the "Announcer Context" is **real-time current conversation state**, not historical. They work together:

| Feature | Timeframe | Purpose |
|---------|-----------|---------|
| Long-term Memory (facts) | Past calls | "User has a dog named Max" |
| Smart Summary | Past calls | "Last call was about job interview prep" |
| **Announcer Context** | **THIS call** | "User seems frustrated, tone shifted 2 min ago" |

---

## Important Note from Dave

### Clarification: Two Different "Layers" Concepts

There's nuanced confusion between:

1. **Research "Layers of Persona"** - Academic concept about persona construction:
   - Character background
   - Personality traits
   - Speaking style
   - Knowledge boundaries
   - etc.

2. **Call Me Back "Layers of Persona Prompt"** - Our implementation architecture:
   - Layer 1: Base persona prompt (core_system_prompt from DB)
   - Layer 2: Call context (callPretext, callScenario)
   - Layer 3: Relationship context (user-defined)
   - Layer 4: User facts (longTermMemory)
   - Layer 5: Phone call guidelines (universal)

**The research layers are about WHAT makes up a persona.**
**Our layers are about HOW we construct the prompt at runtime.**

They're related but distinct concepts. Our implementation layers together different SOURCES of information, while research layers describe different ASPECTS of character.

---

## Next Session Priorities

### P0 - MUST DO
1. **Stripe Go-Live** (carried forward)
   - Switch to live API keys
   - Recreate products/prices in live mode
   - Update webhook endpoint
   - Full checklist in previous NSL

### P1 - Should Do
1. **Fix admin dashboard profit calculations**
   - `projectedNetProfit = revenue - apiCosts - liability` (not just revenue - liability)

2. **Implement Silence-Aware Context**
   - Add `silenceContext` field to VoicePipeline
   - Inject into `buildFullSystemPrompt()`
   - Test with different silence durations

### P2 - Future
1. **Implement Announcer Context**
   - Design state tracking (tone, phase, emotional arc)
   - Create injection format
   - Test impact on response quality

2. **Apply Persona Prompt Upgrades**
   - Anti-slop rules
   - Behavioral constraints
   - Vocabulary lists
   - See: `docs/PERSONA_PROMPT_AUDIT_AND_RECOMMENDATIONS.md`

3. **Smart Summary Integration**
   - Design summary format
   - Integrate with conversation state

---

## Files Created This Session

| File | Purpose |
|------|---------|
| `docs/session_logs/NEXT_SESSION_LOG_2025-12-03_03-11_VULTR_UPGRADE_AND_DEPLOY.md` | Previous session: deployment + infra |
| `docs/PERSONA_PROMPT_AUDIT_AND_RECOMMENDATIONS.md` | Full persona prompt audit with upgrade recommendations |
| `docs/session_logs/NEXT_SESSION_LOG_2025-12-03_03-45_CONTEXT_AWARE_PROMPTING.md` | This file |

---

## Reference Links

- [awesome-llm-role-playing-with-persona](https://github.com/Neph0s/awesome-llm-role-playing-with-persona)
- [awesome-llama-prompts](https://github.com/langgptai/awesome-llama-prompts)
- [Roleplay-Hermes-3-Llama-3.1-8B](https://huggingface.co/vicgalle/Roleplay-Hermes-3-Llama-3.1-8B)
- [Meta Llama Prompting Guide](https://www.llama.com/docs/how-to-guides/prompting/)
- [PromptHub Persona Research](https://www.prompthub.us/blog/role-prompting-does-adding-personas-to-your-prompts-really-make-a-difference)

---

## Context at Session End

- 4% context remaining
- Raindrop deployed, Voice Pipeline deployed
- Caddy fixed (was conflicting with nginx)
- Vultr upgraded to $20/mo tier
- Build snapshot created for fast deploys

---

**End of Session Log**
