# Log Query & Cost Aggregation Service

**Version:** 1.0.0
**Purpose:** Real-time cost tracking and log aggregation for Call Me Back
**Status:** âœ… FULLY OPERATIONAL (voice-pipeline integration complete 2025-11-19)

## âœ… Integration Status

- âœ… Voice-pipeline logging Cerebras usage (model + tokens)
- âœ… Voice-pipeline logging ElevenLabs character counts
- âœ… Voice-pipeline logging Deepgram duration/confidence
- âœ… Collectors ready to parse all usage data
- âœ… Service deployed to Vultr
- ğŸ”² Awaiting first test call to validate end-to-end

---

## Overview

This service aggregates logs from multiple sources (Twilio, Vultr voice-pipeline, AI services) and calculates per-call costs for the Call Me Back application. It writes cost data to PostgreSQL for profitability analysis.

### Key Features

- âœ… **Multi-Source Log Aggregation:** Twilio API + Vultr PM2 logs
- âœ… **AI Service Cost Tracking:** Deepgram, Cerebras, ElevenLabs (parsed from voice-pipeline logs)
- âœ… **Real-Time Cost Calculation:** Per-call cost breakdowns with profit/margin
- âœ… **Database Integration:** Writes to `call_cost_events` table
- âœ… **Caching:** 5-minute cache for frequently accessed data
- âœ… **REST API:** Simple HTTP endpoints for cost queries

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PRIMARY DATA SOURCE: Vultr Voice Pipeline      â”‚
â”‚ /var/log/pm2/voice-pipeline-out.log           â”‚
â”‚                                                â”‚
â”‚ Contains ALL AI service usage:                 â”‚
â”‚ â€¢ Deepgram STT transcripts & duration         â”‚
â”‚ â€¢ Cerebras inference token counts              â”‚
â”‚ â€¢ ElevenLabs TTS character counts              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Log Collectors     â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ â€¢ VultrCollector     â”‚ â† PRIMARY (reads PM2 logs)
         â”‚ â€¢ TwilioCollector    â”‚ â† Calls Twilio API
         â”‚ â€¢ DeepgramCollector  â”‚ â† Parses Vultr logs
         â”‚ â€¢ CerebrasCollector  â”‚ â† Parses Vultr logs
         â”‚ â€¢ ElevenLabsCollectorâ”‚ â† Parses Vultr logs
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Usage Tracker      â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ â€¢ Aggregates usage   â”‚
         â”‚ â€¢ Calculates costs   â”‚
         â”‚ â€¢ Applies pricing    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   REST API Endpoints â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ GET  /api/usage/call/:id       â”‚
         â”‚ POST /api/usage/calculate      â”‚
         â”‚ GET  /health                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   PostgreSQL DB      â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ â€¢ call_cost_events   â”‚
         â”‚ â€¢ calls (update)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## API Endpoints

### GET /health
Health check endpoint

**Response:**
```json
{
  "status": "healthy",
  "timestamp": "2025-11-19T...",
  "version": "1.0.0",
  "service": "log-query-service"
}
```

### GET /api/usage/call/:callId
Get cost breakdown for a specific call

**Parameters:**
- `callId` (path): Call ID from database

**Response:**
```json
{
  "callId": "uuid-here",
  "usage": {
    "twilio": { "duration_seconds": 300, "duration_minutes": 5 },
    "deepgram": { "duration_minutes": 5, "transcript_length": 1234 },
    "cerebras": { "total_tokens": 5000 },
    "elevenlabs": { "total_characters": 2000 }
  },
  "costs": {
    "twilio": 0.07,
    "deepgram": 0.02945,
    "cerebras": 0.0005,
    "elevenlabs": 0.30
  },
  "subtotal": 0.40,
  "totalCost": 0.875,
  "profit": 4.115,
  "margin": "82.47%"
}
```

### POST /api/usage/calculate
Calculate costs and write to database

**Body:**
```json
{
  "callId": "uuid-here",
  "userId": "uuid-here"
}
```

**Response:**
```json
{
  "success": true,
  "callId": "uuid-here",
  "costBreakdown": { ... },
  "message": "Cost data written to call_cost_events table"
}
```

---

## Installation

### Local Development

```bash
npm install
./setup-env.sh  # Creates .env from root .env
npm start
```

### Vultr Deployment

```bash
./deploy.sh
```

See [DEPLOYMENT_INSTRUCTIONS.md](./DEPLOYMENT_INSTRUCTIONS.md) for full deployment guide.

---

## Expected Log Formats (2025-11-19)

The collectors parse these exact patterns from voice-pipeline logs:

**Cerebras:**
```
[VoicePipeline CA...] Cerebras usage: model: llama3.1-8b prompt_tokens: 25 completion_tokens: 50 total_tokens: 75
```

**ElevenLabs:**
```
[VoicePipeline CA...] ElevenLabs TTS: characters: 145 voice_id: pNInz6obpgDQGcFmaJgB model: eleven_turbo_v2_5
```

**Deepgram:**
```
[VoicePipeline CA...] Deepgram transcript: duration: 2.5 confidence: 0.95 is_final: true
```

Parsers: See `collectors/cerebras.js`, `collectors/elevenlabs.js`, `collectors/deepgram.js`

---

## Cost Breakdown (Per 5-min Call)

Based on 2025-01 pricing:

| Service     | Cost/Call | % of Total |
|-------------|-----------|------------|
| Twilio      | $0.070    | 16%        |
| Deepgram    | $0.030    | 7%         |
| Cerebras    | $0.005    | 1%         |
| ElevenLabs  | $0.300    | 70%  â­    |
| Raindrop    | $0.020    | 5%         |
| **Subtotal**| **$0.425**| **100%**   |
| Stripe      | $0.475    | (payment)  |
| **Total**   | **$0.900**|            |

**User Charge:** $4.99
**Profit:** $4.09
**Margin:** 82%

**Key Insight:** ElevenLabs TTS is 70% of API costs - primary optimization target.

---

## Security (Updated 2025-11-19)

**âœ… SECURE: Localhost-only binding**

This service is bound to `localhost:3001` and is **NOT accessible from the internet**. It can only be accessed from:
- The Vultr server itself (localhost)
- Other services running on the same Vultr server
- The `cost-analytics` Raindrop service (server-to-server via internal URL)

**Architecture:**
```
User â†’ Frontend (Vercel) â†’ API Gateway (Raindrop) â†’ cost-analytics (Raindrop)
                                                          â†“
                                            log-query-service (Vultr localhost:3001)
```

**Why this is secure:**
- No public network exposure
- No authentication needed (localhost-only access)
- Cannot be reached from external networks
- Protected by Vultr firewall

**For production:**
- Consider moving behind VPN for multi-server setups
- Add HTTPS if exposing beyond localhost
- Implement proper authentication if making public

---

## Environment Variables

```bash
PORT=3001                              # Service port (bound to localhost only)
NODE_ENV=production                     # Environment
VULTR_VOICE_LOG_PATH=/var/log/pm2/...  # Voice pipeline logs
TWILIO_ACCOUNT_SID=...                  # Twilio API
TWILIO_AUTH_TOKEN=...                   # Twilio API
POSTGRES_HOST=localhost                 # Database
POSTGRES_DB=callmeback                  # Database name
POSTGRES_USER=...                       # Database user
POSTGRES_PASSWORD=...                   # Database password
CACHE_TTL=300                           # Cache duration (seconds)
```

---

## Dependencies

```json
{
  "express": "HTTP server",
  "pg": "PostgreSQL client",
  "axios": "HTTP client for Twilio API",
  "winston": "Logging",
  "node-cache": "In-memory caching",
  "dotenv": "Environment variables",
  "cors": "CORS middleware"
}
```

---

## Directory Structure

```
log-query-service/
â”œâ”€â”€ server.js                 # Main Express app
â”œâ”€â”€ package.json              # Dependencies
â”œâ”€â”€ ecosystem.config.js       # PM2 configuration
â”œâ”€â”€ setup-env.sh             # Environment setup script
â”œâ”€â”€ deploy.sh                # Deployment script
â”œâ”€â”€ collectors/              # Log collection modules
â”‚   â”œâ”€â”€ twilio.js           # Twilio API collector
â”‚   â”œâ”€â”€ vultr.js            # PM2 log reader (PRIMARY)
â”‚   â”œâ”€â”€ deepgram.js         # Parses voice-pipeline logs
â”‚   â”œâ”€â”€ cerebras.js         # Parses voice-pipeline logs
â”‚   â””â”€â”€ elevenlabs.js       # Parses voice-pipeline logs
â”œâ”€â”€ trackers/               # Cost calculation
â”‚   â”œâ”€â”€ pricing-constants.js # API pricing rates
â”‚   â””â”€â”€ usage-tracker.js    # Aggregates usage & calculates costs
â”œâ”€â”€ routes/                 # API endpoints
â”‚   â””â”€â”€ usage/
â”‚       â”œâ”€â”€ call.js         # GET /api/usage/call/:id
â”‚       â””â”€â”€ calculate.js    # POST /api/usage/calculate
â”œâ”€â”€ utils/                  # Utilities
â”‚   â””â”€â”€ database.js         # PostgreSQL integration
â””â”€â”€ README.md              # This file
```

---

## Critical Design Decisions

### 1. Why Parse Logs Instead of Direct API Calls?

**Deepgram, Cerebras, ElevenLabs don't provide usage APIs.** The voice-pipeline service logs ALL usage in real-time to PM2 logs. Parsing these logs is:
- âœ… More accurate (captures actual usage)
- âœ… Faster (no external API calls)
- âœ… Cheaper (no API rate limits)
- âœ… Real-time (log-based)

### 2. Why Separate Service Instead of Raindrop MCP?

**Raindrop MCP framework has known limitations** (see MCP_DEBUGGING_SESSION_2025-11-19.md). This HTTP service:
- âœ… Works reliably (proven pattern)
- âœ… Runs on Vultr (can read local PM2 logs)
- âœ… Uses standard Node.js/Express (no framework dependencies)
- âœ… Can be deployed immediately

### 3. Why PostgreSQL Direct Connection?

**Database-proxy adds latency for bulk writes.** Cost tracking needs:
- Transactions (BEGIN/COMMIT)
- Bulk inserts (4+ events per call)
- Real-time updates

Direct PostgreSQL connection is faster and more reliable.

---

## Future Enhancements

- [ ] WebSocket support for real-time cost streaming during calls
- [ ] Dynamic pricing updates (fetch from external APIs)
- [ ] Cost analytics dashboard
- [ ] Alerting system (budget thresholds)
- [ ] Data retention policies
- [ ] Rate limiting & authentication

---

## Troubleshooting

### "Cannot connect to database"
- Check PostgreSQL is running: `sudo systemctl status postgresql`
- Verify credentials in `.env`
- Test connection: `psql -h localhost -U user -d callmeback`

### "Cannot read log files"
- Check PM2 logs exist: `ls -la /var/log/pm2/voice-pipeline-out.log`
- Verify file permissions
- Check voice-pipeline is running: `pm2 status`

### "No cost data in database"
- Verify `call_cost_events` table exists
- Check service logs: `pm2 logs log-query-service`
- Test POST /api/usage/calculate endpoint

---

## Documentation

- **DEPLOYMENT_INSTRUCTIONS.md** - Full deployment guide
- **PCR2.md** - Project context & architecture
- **LOG_AND_COST_AGGREGATION_SERVICE_PLAN.md** - Original design doc
- **SYSTEM_ARCHITECTURE.md** - Infrastructure overview

---

## Maintenance

### Update Pricing

Edit `trackers/pricing-constants.js` with new rates, then:

```bash
ssh root@144.202.15.249
cd /root/log-query-service
nano trackers/pricing-constants.js
pm2 restart log-query-service
```

### View Logs

```bash
# Live tail
pm2 logs log-query-service -f

# Last 100 lines
pm2 logs log-query-service --lines 100

# Errors only
pm2 logs log-query-service --err
```

### Restart Service

```bash
ssh root@144.202.15.249
pm2 restart log-query-service
```

---

**Status:** âœ… Ready for deployment
**Next Step:** Run `./deploy.sh` to deploy to Vultr
